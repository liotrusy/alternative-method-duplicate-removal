# Alternative Method Duplicate Removal

In this project I explored the possibility to reduce the number of loops used to remove duplicate entries from the dataset. The original version of the solution can be found in [this link](https://github.com/dataquestio/solutions/blob/master/Mission350Solutions.ipynb).

At the end of the project, I was able to improve the performance by 1.5x (reducing the number of loops needed by 10,840). Thanks for the authors of the orignial solution for the interesting analysis! It was an intereseting exploration.
